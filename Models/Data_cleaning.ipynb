{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be training a model That classifies tweets into +ve or -ve.\n",
    "The dataset for training, I chose ‚ÄúSentiment140‚Äù, which originated from Stanford University. More info on the dataset can be found from the link. http://help.sentiment140.com/for-students/\n",
    "The dataset can be downloaded from the below link.\n",
    "http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\n",
    "\n",
    "## Data cleaning\n",
    "Let's look at the data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1546722</th>\n",
       "      <td>4</td>\n",
       "      <td>2182552500</td>\n",
       "      <td>Mon Jun 15 13:19:26 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>fluffyVW</td>\n",
       "      <td>@MartOthman Hehe!!! You finally got you're ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846709</th>\n",
       "      <td>4</td>\n",
       "      <td>1564450670</td>\n",
       "      <td>Mon Apr 20 03:33:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TVFanUK</td>\n",
       "      <td>@Posh_Totty Considering its monday morning, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293392</th>\n",
       "      <td>4</td>\n",
       "      <td>2003203618</td>\n",
       "      <td>Tue Jun 02 06:05:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jayzed77</td>\n",
       "      <td>Track and field today  wish me luck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79882</th>\n",
       "      <td>0</td>\n",
       "      <td>1752047704</td>\n",
       "      <td>Sat May 09 20:55:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jackswilgafee</td>\n",
       "      <td>http://twitpic.com/4wds1 - this chinchilla did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323369</th>\n",
       "      <td>4</td>\n",
       "      <td>2014896182</td>\n",
       "      <td>Wed Jun 03 03:02:36 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>alyssaalmighty</td>\n",
       "      <td>@emmzalmighty hey im cooler than you bitch, @J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342503</th>\n",
       "      <td>0</td>\n",
       "      <td>2015270092</td>\n",
       "      <td>Wed Jun 03 04:11:58 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>wanfaws</td>\n",
       "      <td>@ahmadzul i agree with you about blocking twit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350557</th>\n",
       "      <td>4</td>\n",
       "      <td>2045618468</td>\n",
       "      <td>Fri Jun 05 10:59:30 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>belcomputer521</td>\n",
       "      <td>Tonight we're going to a Fashion design school...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569754</th>\n",
       "      <td>0</td>\n",
       "      <td>2208081093</td>\n",
       "      <td>Wed Jun 17 08:45:20 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LillianJulia</td>\n",
       "      <td>@CMStevens I will give that a whirl! every tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170241</th>\n",
       "      <td>4</td>\n",
       "      <td>1980352385</td>\n",
       "      <td>Sun May 31 06:29:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>coniina</td>\n",
       "      <td>Doing the hoedown!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188318</th>\n",
       "      <td>4</td>\n",
       "      <td>1983310725</td>\n",
       "      <td>Sun May 31 12:54:48 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>kthugnasty</td>\n",
       "      <td>Victoria's House for Lab</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment          id                          date     query  \\\n",
       "1546722          4  2182552500  Mon Jun 15 13:19:26 PDT 2009  NO_QUERY   \n",
       "846709           4  1564450670  Mon Apr 20 03:33:03 PDT 2009  NO_QUERY   \n",
       "1293392          4  2003203618  Tue Jun 02 06:05:12 PDT 2009  NO_QUERY   \n",
       "79882            0  1752047704  Sat May 09 20:55:33 PDT 2009  NO_QUERY   \n",
       "1323369          4  2014896182  Wed Jun 03 03:02:36 PDT 2009  NO_QUERY   \n",
       "342503           0  2015270092  Wed Jun 03 04:11:58 PDT 2009  NO_QUERY   \n",
       "1350557          4  2045618468  Fri Jun 05 10:59:30 PDT 2009  NO_QUERY   \n",
       "569754           0  2208081093  Wed Jun 17 08:45:20 PDT 2009  NO_QUERY   \n",
       "1170241          4  1980352385  Sun May 31 06:29:33 PDT 2009  NO_QUERY   \n",
       "1188318          4  1983310725  Sun May 31 12:54:48 PDT 2009  NO_QUERY   \n",
       "\n",
       "                   user                                               text  \n",
       "1546722        fluffyVW  @MartOthman Hehe!!! You finally got you're ste...  \n",
       "846709          TVFanUK  @Posh_Totty Considering its monday morning, no...  \n",
       "1293392        jayzed77                Track and field today  wish me luck  \n",
       "79882     jackswilgafee  http://twitpic.com/4wds1 - this chinchilla did...  \n",
       "1323369  alyssaalmighty  @emmzalmighty hey im cooler than you bitch, @J...  \n",
       "342503          wanfaws  @ahmadzul i agree with you about blocking twit...  \n",
       "1350557  belcomputer521  Tonight we're going to a Fashion design school...  \n",
       "569754     LillianJulia  @CMStevens I will give that a whirl! every tim...  \n",
       "1170241         coniina                              Doing the hoedown!!!   \n",
       "1188318      kthugnasty                          Victoria's House for Lab   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cols=['sentiment','id','date','query','user','text']\n",
    "df = pd.read_csv(\"training.csv\" ,header=None,encoding='latin-1',names=cols)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the polarity of the tweet (0 = negative, 4 = positive)'\n",
    "\n",
    "Let's drop unnecessary columns like id, user, date, query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['id','date','query','user'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          0  is upset that he can't update his Facebook by ...\n",
       "2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment==0].head() #negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          sentiment                                               text\n",
       "800000           4       I LOVE @Health4UandPets u guys r the best!! \n",
       "800001           4  im meeting up with one of my besties tonight! ...\n",
       "800002           4  @DaRealSunisaKim Thanks for the Twitter add, S...\n",
       "800003           4  Being sick can be really cheap when it hurts t...\n",
       "800004           4    @LovesBrooklyn2 he has that effect on everyone \n",
       "...            ...                                                ...\n",
       "1599995          4  Just woke up. Having no school is the best fee...\n",
       "1599996          4  TheWDB.com - Very cool to hear old Walt interv...\n",
       "1599997          4  Are you ready for your MoJo Makeover? Ask me f...\n",
       "1599998          4  Happy 38th Birthday to my boo of alll time!!! ...\n",
       "1599999          4  happy #charitytuesday @theNSPCC @SparksCharity...\n",
       "\n",
       "[800000 rows x 2 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment==4].head #positive tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 8,00,000 tweets for each category,, so in total there are 16,00,000 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>pre_clean_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                               text  \\\n",
       "0                0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1                0  is upset that he can't update his Facebook by ...   \n",
       "2                0  @Kenichan I dived many times for the ball. Man...   \n",
       "3                0    my whole body feels itchy and like its on fire    \n",
       "4                0  @nationwideclass no, it's not behaving at all....   \n",
       "...            ...                                                ...   \n",
       "1599995          4  Just woke up. Having no school is the best fee...   \n",
       "1599996          4  TheWDB.com - Very cool to hear old Walt interv...   \n",
       "1599997          4  Are you ready for your MoJo Makeover? Ask me f...   \n",
       "1599998          4  Happy 38th Birthday to my boo of alll time!!! ...   \n",
       "1599999          4  happy #charitytuesday @theNSPCC @SparksCharity...   \n",
       "\n",
       "         pre_clean_len  \n",
       "0                  115  \n",
       "1                  111  \n",
       "2                   89  \n",
       "3                   47  \n",
       "4                  111  \n",
       "...                ...  \n",
       "1599995             56  \n",
       "1599996             78  \n",
       "1599997             57  \n",
       "1599998             65  \n",
       "1599999             62  \n",
       "\n",
       "[1600000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pre_clean_len'] = [len(t) for t in df.text]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of overall length of strings in each record\n",
    "\n",
    "Im gonna plot a box plot..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(df.pre_clean_len)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems strange cz the tweet limit is 140 characters, lets dive into this situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>pre_clean_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223805</th>\n",
       "      <td>0</td>\n",
       "      <td>i pressed something..now i can`t use d AT symb...</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068013</th>\n",
       "      <td>4</td>\n",
       "      <td>&amp;quot;No one knows me better than I know mysel...</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962715</th>\n",
       "      <td>4</td>\n",
       "      <td>'Time Is An Illusion and All Time Is Now'... &amp;...</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898562</th>\n",
       "      <td>4</td>\n",
       "      <td>@Jerzy You could pick out characters you both ...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260974</th>\n",
       "      <td>4</td>\n",
       "      <td>Trying to adjust to everyone knowing what Nata...</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489287</th>\n",
       "      <td>4</td>\n",
       "      <td>@gfalcone601  Just a silly question... have yo...</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355049</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm really tired...the &amp;quot;not sick&amp;quot; ca...</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251223</th>\n",
       "      <td>4</td>\n",
       "      <td>@nikiblack no thanks.  Editing something I wro...</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030271</th>\n",
       "      <td>4</td>\n",
       "      <td>@fauxparse Just discovered that Firefox doesn'...</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010637</th>\n",
       "      <td>4</td>\n",
       "      <td>@caffeinebomb good lunch  although they gavre ...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                               text  \\\n",
       "223805           0  i pressed something..now i can`t use d AT symb...   \n",
       "1068013          4  &quot;No one knows me better than I know mysel...   \n",
       "962715           4  'Time Is An Illusion and All Time Is Now'... &...   \n",
       "898562           4  @Jerzy You could pick out characters you both ...   \n",
       "1260974          4  Trying to adjust to everyone knowing what Nata...   \n",
       "1489287          4  @gfalcone601  Just a silly question... have yo...   \n",
       "355049           0  I'm really tired...the &quot;not sick&quot; ca...   \n",
       "1251223          4  @nikiblack no thanks.  Editing something I wro...   \n",
       "1030271          4  @fauxparse Just discovered that Firefox doesn'...   \n",
       "1010637          4  @caffeinebomb good lunch  although they gavre ...   \n",
       "\n",
       "         pre_clean_len  \n",
       "223805             145  \n",
       "1068013            152  \n",
       "962715             147  \n",
       "898562             141  \n",
       "1260974            148  \n",
       "1489287            143  \n",
       "355049             148  \n",
       "1251223            142  \n",
       "1030271            151  \n",
       "1010637            141  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.pre_clean_len > 140].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks like it's cleaning time üëÄ\n",
    "\n",
    "- HTML decoding (&amp, &quot..)\n",
    "- negation handling\n",
    "- '@' twitter id removing\n",
    "- URL links( http pattern, www pattern)\n",
    "- Utf Byte Order Mark (\\xef\\xbf\\xbd)\n",
    "- Hashtag symbol\n",
    "- lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "\n",
    "pattern1= r'@[A-za-z0-9_]+'\n",
    "pattern2= r'https?://[^ ]+'\n",
    "pattern3 = r'www.[^ ]+'\n",
    "combined =  r'|'.join((pattern1, pattern2))\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "def cleaner(text):\n",
    "    #html decoding\n",
    "    soup = BeautifulSoup(text,'lxml')\n",
    "    souped = soup.get_text()\n",
    "    try:    \n",
    "    #BOM\n",
    "        clean = souped.decode(\"utf-8-sig\").replace(u\"ufffd\", \"?\")\n",
    "    except:\n",
    "        clean=souped\n",
    "    stripped = re.sub(combined,'',clean)\n",
    "    stripped = re.sub(pattern3,'',stripped)\n",
    "    #removing numbers and converting to lowercase\n",
    "    lower_case = stripped.lower() \n",
    "    neg = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg)\n",
    "     \n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = tok.tokenize(lower_case)\n",
    "    return (\" \".join(words)).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "Tweets 10000 of 1600000 has been processed\n",
      "Tweets 20000 of 1600000 has been processed\n",
      "Tweets 30000 of 1600000 has been processed\n",
      "Tweets 40000 of 1600000 has been processed\n",
      "Tweets 50000 of 1600000 has been processed\n",
      "Tweets 60000 of 1600000 has been processed\n",
      "Tweets 70000 of 1600000 has been processed\n",
      "Tweets 80000 of 1600000 has been processed\n",
      "Tweets 90000 of 1600000 has been processed\n",
      "Tweets 100000 of 1600000 has been processed\n",
      "Tweets 110000 of 1600000 has been processed\n",
      "Tweets 120000 of 1600000 has been processed\n",
      "Tweets 130000 of 1600000 has been processed\n",
      "Tweets 140000 of 1600000 has been processed\n",
      "Tweets 150000 of 1600000 has been processed\n",
      "Tweets 160000 of 1600000 has been processed\n",
      "Tweets 170000 of 1600000 has been processed\n",
      "Tweets 180000 of 1600000 has been processed\n",
      "Tweets 190000 of 1600000 has been processed\n",
      "Tweets 200000 of 1600000 has been processed\n",
      "Tweets 210000 of 1600000 has been processed\n",
      "Tweets 220000 of 1600000 has been processed\n",
      "Tweets 230000 of 1600000 has been processed\n",
      "Tweets 240000 of 1600000 has been processed\n",
      "Tweets 250000 of 1600000 has been processed\n",
      "Tweets 260000 of 1600000 has been processed\n",
      "Tweets 270000 of 1600000 has been processed\n",
      "Tweets 280000 of 1600000 has been processed\n",
      "Tweets 290000 of 1600000 has been processed\n",
      "Tweets 300000 of 1600000 has been processed\n",
      "Tweets 310000 of 1600000 has been processed\n",
      "Tweets 320000 of 1600000 has been processed\n",
      "Tweets 330000 of 1600000 has been processed\n",
      "Tweets 340000 of 1600000 has been processed\n",
      "Tweets 350000 of 1600000 has been processed\n",
      "Tweets 360000 of 1600000 has been processed\n",
      "Tweets 370000 of 1600000 has been processed\n",
      "Tweets 380000 of 1600000 has been processed\n",
      "Tweets 390000 of 1600000 has been processed\n",
      "Tweets 400000 of 1600000 has been processed\n",
      "Tweets 410000 of 1600000 has been processed\n",
      "Tweets 420000 of 1600000 has been processed\n",
      "Tweets 430000 of 1600000 has been processed\n",
      "Tweets 440000 of 1600000 has been processed\n",
      "Tweets 450000 of 1600000 has been processed\n",
      "Tweets 460000 of 1600000 has been processed\n",
      "Tweets 470000 of 1600000 has been processed\n",
      "Tweets 480000 of 1600000 has been processed\n",
      "Tweets 490000 of 1600000 has been processed\n",
      "Tweets 500000 of 1600000 has been processed\n",
      "Tweets 510000 of 1600000 has been processed\n",
      "Tweets 520000 of 1600000 has been processed\n",
      "Tweets 530000 of 1600000 has been processed\n",
      "Tweets 540000 of 1600000 has been processed\n",
      "Tweets 550000 of 1600000 has been processed\n",
      "Tweets 560000 of 1600000 has been processed\n",
      "Tweets 570000 of 1600000 has been processed\n",
      "Tweets 580000 of 1600000 has been processed\n",
      "Tweets 590000 of 1600000 has been processed\n",
      "Tweets 600000 of 1600000 has been processed\n",
      "Tweets 610000 of 1600000 has been processed\n",
      "Tweets 620000 of 1600000 has been processed\n",
      "Tweets 630000 of 1600000 has been processed\n",
      "Tweets 640000 of 1600000 has been processed\n",
      "Tweets 650000 of 1600000 has been processed\n",
      "Tweets 660000 of 1600000 has been processed\n",
      "Tweets 670000 of 1600000 has been processed\n",
      "Tweets 680000 of 1600000 has been processed\n",
      "Tweets 690000 of 1600000 has been processed\n",
      "Tweets 700000 of 1600000 has been processed\n",
      "Tweets 710000 of 1600000 has been processed\n",
      "Tweets 720000 of 1600000 has been processed\n",
      "Tweets 730000 of 1600000 has been processed\n",
      "Tweets 740000 of 1600000 has been processed\n",
      "Tweets 750000 of 1600000 has been processed\n",
      "Tweets 760000 of 1600000 has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saniy\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b' i just received my G8 viola exam.. and its... well... .. disappointing.. :\\\\..'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets 770000 of 1600000 has been processed\n",
      "Tweets 780000 of 1600000 has been processed\n",
      "Tweets 790000 of 1600000 has been processed\n",
      "Tweets 800000 of 1600000 has been processed\n",
      "Tweets 810000 of 1600000 has been processed\n",
      "Tweets 820000 of 1600000 has been processed\n",
      "Tweets 830000 of 1600000 has been processed\n",
      "Tweets 840000 of 1600000 has been processed\n",
      "Tweets 850000 of 1600000 has been processed\n",
      "Tweets 860000 of 1600000 has been processed\n",
      "Tweets 870000 of 1600000 has been processed\n",
      "Tweets 880000 of 1600000 has been processed\n",
      "Tweets 890000 of 1600000 has been processed\n",
      "Tweets 900000 of 1600000 has been processed\n",
      "Tweets 910000 of 1600000 has been processed\n",
      "Tweets 920000 of 1600000 has been processed\n",
      "Tweets 930000 of 1600000 has been processed\n",
      "Tweets 940000 of 1600000 has been processed\n",
      "Tweets 950000 of 1600000 has been processed\n",
      "Tweets 960000 of 1600000 has been processed\n",
      "Tweets 970000 of 1600000 has been processed\n",
      "Tweets 980000 of 1600000 has been processed\n",
      "Tweets 990000 of 1600000 has been processed\n",
      "Tweets 1000000 of 1600000 has been processed\n",
      "Tweets 1010000 of 1600000 has been processed\n",
      "Tweets 1020000 of 1600000 has been processed\n",
      "Tweets 1030000 of 1600000 has been processed\n",
      "Tweets 1040000 of 1600000 has been processed\n",
      "Tweets 1050000 of 1600000 has been processed\n",
      "Tweets 1060000 of 1600000 has been processed\n",
      "Tweets 1070000 of 1600000 has been processed\n",
      "Tweets 1080000 of 1600000 has been processed\n",
      "Tweets 1090000 of 1600000 has been processed\n",
      "Tweets 1100000 of 1600000 has been processed\n",
      "Tweets 1110000 of 1600000 has been processed\n",
      "Tweets 1120000 of 1600000 has been processed\n",
      "Tweets 1130000 of 1600000 has been processed\n",
      "Tweets 1140000 of 1600000 has been processed\n",
      "Tweets 1150000 of 1600000 has been processed\n",
      "Tweets 1160000 of 1600000 has been processed\n",
      "Tweets 1170000 of 1600000 has been processed\n",
      "Tweets 1180000 of 1600000 has been processed\n",
      "Tweets 1190000 of 1600000 has been processed\n",
      "Tweets 1200000 of 1600000 has been processed\n",
      "Tweets 1210000 of 1600000 has been processed\n",
      "Tweets 1220000 of 1600000 has been processed\n",
      "Tweets 1230000 of 1600000 has been processed\n",
      "Tweets 1240000 of 1600000 has been processed\n",
      "Tweets 1250000 of 1600000 has been processed\n",
      "Tweets 1260000 of 1600000 has been processed\n",
      "Tweets 1270000 of 1600000 has been processed\n",
      "Tweets 1280000 of 1600000 has been processed\n",
      "Tweets 1290000 of 1600000 has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saniy\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'E3 ON PLAYSTATION HOME IN ABOUT AN HOUR!!!!!!!!!! \\\\../  \\\\../'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets 1300000 of 1600000 has been processed\n",
      "Tweets 1310000 of 1600000 has been processed\n",
      "Tweets 1320000 of 1600000 has been processed\n",
      "Tweets 1330000 of 1600000 has been processed\n",
      "Tweets 1340000 of 1600000 has been processed\n",
      "Tweets 1350000 of 1600000 has been processed\n",
      "Tweets 1360000 of 1600000 has been processed\n",
      "Tweets 1370000 of 1600000 has been processed\n",
      "Tweets 1380000 of 1600000 has been processed\n",
      "Tweets 1390000 of 1600000 has been processed\n",
      "Tweets 1400000 of 1600000 has been processed\n",
      "Tweets 1410000 of 1600000 has been processed\n",
      "Tweets 1420000 of 1600000 has been processed\n",
      "Tweets 1430000 of 1600000 has been processed\n",
      "Tweets 1440000 of 1600000 has been processed\n",
      "Tweets 1450000 of 1600000 has been processed\n",
      "Tweets 1460000 of 1600000 has been processed\n",
      "Tweets 1470000 of 1600000 has been processed\n",
      "Tweets 1480000 of 1600000 has been processed\n",
      "Tweets 1490000 of 1600000 has been processed\n",
      "Tweets 1500000 of 1600000 has been processed\n",
      "Tweets 1510000 of 1600000 has been processed\n",
      "Tweets 1520000 of 1600000 has been processed\n",
      "Tweets 1530000 of 1600000 has been processed\n",
      "Tweets 1540000 of 1600000 has been processed\n",
      "Tweets 1550000 of 1600000 has been processed\n",
      "Tweets 1560000 of 1600000 has been processed\n",
      "Tweets 1570000 of 1600000 has been processed\n",
      "Tweets 1580000 of 1600000 has been processed\n",
      "Tweets 1590000 of 1600000 has been processed\n",
      "Tweets 1600000 of 1600000 has been processed\n"
     ]
    }
   ],
   "source": [
    "nums = [0,1600000]\n",
    "print( \"Cleaning and parsing the tweets...\\n\")\n",
    "clean_tweet_texts = []\n",
    "for i in range(nums[0],nums[1]):\n",
    "    if( (i+1)%10000 == 0 ):\n",
    "        print(\"Tweets %d of %d has been processed\" % ( i+1, nums[1] ))                                                           \n",
    "    clean_tweet_texts.append(cleaner(df['text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_tweet_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>868824</th>\n",
       "      <td>those situations are irrelevant now . doing na...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277314</th>\n",
       "      <td>got woken up by a phone call from work , askin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468914</th>\n",
       "      <td>thanks for letting me follow you</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  target\n",
       "868824   those situations are irrelevant now . doing na...       4\n",
       "277314   got woken up by a phone call from work , askin...       0\n",
       "1468914                   thanks for letting me follow you       4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.DataFrame(clean_tweet_texts,columns=['text'])\n",
    "clean_df['target'] = df.sentiment\n",
    "clean_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv('clean_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
